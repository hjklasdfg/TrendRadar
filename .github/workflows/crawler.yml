name: Hot News Crawler

on:
  schedule:
    # æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ github å®˜æ–¹æä¾›çš„èµ„æºæ¥è¿›è¡Œçš„æ¨é€ï¼Œè€Œæ¯ä¸ªè´¦å·çš„èµ„æºæ˜¯é™é¢çš„ï¼Œä¸ºäº†ä¸è¢«å®˜æ–¹åˆ¤å®šä¸ºæ»¥ç”¨è€Œé¢ä¸´å°å·çš„é£é™©ï¼Œä¸å»ºè®®æ¯”åŠå°æ—¶æ›´ä½
    - cron: "0 * * * *"
  workflow_dispatch:

# Pages éœ€è¦ pages + id-token
permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Verify required files
        run: |
          echo "ğŸ” æ£€æŸ¥å¿…éœ€çš„é…ç½®æ–‡ä»¶..."

          if [ ! -f config/config.yaml ]; then
            echo "âŒ é”™è¯¯: config/config.yaml æ–‡ä»¶ä¸å­˜åœ¨"
            echo "è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£åˆ›å»ºé…ç½®æ–‡ä»¶"
            exit 1
          fi

          if [ ! -f config/frequency_words.txt ]; then
            echo "âŒ é”™è¯¯: config/frequency_words.txt æ–‡ä»¶ä¸å­˜åœ¨"
            echo "è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£åˆ›å»ºé¢‘ç‡è¯é…ç½®æ–‡ä»¶"
            exit 1
          fi

          echo "âœ… é…ç½®æ–‡ä»¶æ£€æŸ¥é€šè¿‡"

      - name: Run crawler
        env:
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          WEWORK_WEBHOOK_URL: ${{ secrets.WEWORK_WEBHOOK_URL }}
          EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
          EMAIL_SMTP_SERVER: ${{ secrets.EMAIL_SMTP_SERVER }}
          EMAIL_SMTP_PORT: ${{ secrets.EMAIL_SMTP_PORT }}
          NTFY_TOPIC: ${{ secrets.NTFY_TOPIC }}
          NTFY_SERVER_URL: ${{ secrets.NTFY_SERVER_URL }}
          NTFY_TOKEN: ${{ secrets.NTFY_TOKEN }}
          GITHUB_ACTIONS: true
        run: python main.py

      - name: Copy latest summary to index.html
        run: |
          # æ‰¾åˆ° output ç›®å½•ä¸‹æœ€æ–°çš„æ—¥æœŸç›®å½•
          latest_dir=$(ls -d output/*/ 2>/dev/null | sort | tail -n 1 || echo "")
          echo "Latest dir: $latest_dir"

          if [ -z "$latest_dir" ]; then
            echo "No output directory found, skip index.html update."
            exit 0
          fi

          summary_file="$latest_dir/html/å½“æ—¥æ±‡æ€».html"

          if [ -f "$summary_file" ]; then
            cp "$summary_file" output/index.html
            echo "Copied $summary_file to output/index.html"
          else
            echo "Summary file not found: $summary_file"
          fi

      - name: Commit and push if changes
        run: |
          git config --global user.name 'GitHub Actions'
          git config --global user.email 'actions@github.com'
          git add -A
          git diff --quiet && git diff --staged --quiet || (git commit -m "Auto update by GitHub Actions at $(TZ=Asia/Shanghai date)" && git push)

      # âœ… å…³é”®ï¼šåœ¨ crawl è¿™é‡Œä¸Šä¼  output ä½œä¸º Pages artifact
      - name: Upload output directory as artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./output

  # åªè´Ÿè´£å‘å¸ƒï¼Œä¸å†åš checkout/upload
  deploy:
    needs: crawl
    runs-on: ubuntu-latest

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
